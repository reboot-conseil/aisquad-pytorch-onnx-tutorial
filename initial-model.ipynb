{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting a `fastai` model to ONNX format\n",
    "\n",
    "This notebook presents the general process of exporting a `fastai` model to ONNX format. The model is trained on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get necessary libraries\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastbook import *\n",
    "from fastai.imports import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.utils import *\n",
    "from fastai.vision.widgets import *\n",
    "from fastcore.all import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/yactouat/.fastai/data/mnist_png/testing'),Path('/home/yactouat/.fastai/data/mnist_png/training')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get MNIST dataset using `fastai` helpers\n",
    "path = untar_data(URLs.MNIST)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a first iteration of a `torch` pre trained model on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_digits_path = Path(path.ls()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `fastai` data loaders to load the MNIST dataset. Data loaders play a crucial role as they:\n",
    "\n",
    "- load the data into the model in batches\n",
    "- apply transformations to the data\n",
    "- split the data into training and validation sets\n",
    "- shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a `fastai` data loader,\n",
    "# this will create random batches of data for training and validation\n",
    "mnist_data_block = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    # this says that the parent folder name of the image will be its label\n",
    "    get_y=parent_label,\n",
    "    splitter=RandomSplitter(valid_pct=0.2)\n",
    ")\n",
    "\n",
    "# the data loader will feed the images to the model in batches of 64,\n",
    "# specifying the number of workers to 4 will allow to parallelize the loading of the images\n",
    "mnist_data_loader = mnist_data_block.dataloaders(mnist_train_digits_path, bs=64, num_workers=4)\n",
    "mnist_data_loader.show_batch(max_n=9)\n",
    "\n",
    "# ! althuough you can't see it here, images undergo some transformations as pre processing steps (this will have its importance later on, when we will try to convert the model to ONNX format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       " (#10) [Path('/home/yactouat/.fastai/data/mnist_png/training/6'),Path('/home/yactouat/.fastai/data/mnist_png/training/4'),Path('/home/yactouat/.fastai/data/mnist_png/training/9'),Path('/home/yactouat/.fastai/data/mnist_png/training/7'),Path('/home/yactouat/.fastai/data/mnist_png/training/3'),Path('/home/yactouat/.fastai/data/mnist_png/training/5'),Path('/home/yactouat/.fastai/data/mnist_png/training/8'),Path('/home/yactouat/.fastai/data/mnist_png/training/2'),Path('/home/yactouat/.fastai/data/mnist_png/training/1'),Path('/home/yactouat/.fastai/data/mnist_png/training/0')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if the data loader categories (labels) are correct\n",
    "mnist_data_loader.vocab, mnist_train_digits_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAD1CAYAAABk3mnHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbn0lEQVR4nO3de5DWZfkH4HuBPCACiigmckqtNiLRCcvABihATWPFw3SUccxDCVLjCErlabQEzUNqeMbj6CTmkCdQQozSMlMRU0DAEgUkS0pEBdnfH03+0nqeXV8W3vdZruu//PD9PrfGg/vxhb3rGhsbGwMAAAAK1abaAwAAAMDGUGwBAAAommILAABA0RRbAAAAiqbYAgAAUDTFFgAAgKIptgAAABRNsQUAAKBoii0AAABFU2wBAAAommJbmHvuuSeGDRsW3bt3j2233Tb69OkTRxxxRDzyyCPVHg1ohldffTWuueaaaGhoiD322CO23Xbb6NSpUwwcODCuvfba2LBhQ7VHBD6AWbNmRUNDQ3Tr1i223nrr+PCHPxzDhw+Pe++9t9qjAc0wfvz4GDp0aOy+++6x7bbbxo477hj9+/ePs846K1599dVqj8cHUNfY2NhY7SFonvHjx8ekSZOiS5cuMXLkyNhpp53i+eefj+nTp8f69evjxhtvjK9//evVHhPImDJlSpx44omx6667xuDBg6NHjx6xcuXKuPPOO2P16tUxatSo+PnPfx51dXXVHhVowqmnnhqTJ0+O7t27x4EHHhg77bRTrFq1Kh5//PH4whe+EJMmTar2iEATttpqq9hnn32ivr4+dt5551izZk08+uij8Yc//CE+/OEPx6OPPhq77757tcekGRTbQqxYsSJ222236Nq1a8ybNy923nnnd7PZs2fHkCFDonfv3rFkyZIqTgk05Ve/+lWsWbMmDj744GjT5v9/08yKFStiwIAB8eKLL8Ydd9wRo0aNquKUQFOuvvrqOO644+Loo4+Oq666Krbaaqv35OvWrYsPfehDVZoOaK4333wzttlmm//66xMnTozzzjsvTjzxxLjiiiuqMBkflN+KXIg///nPsWHDhthvv/3eU2ojIgYPHhzbb799rFq1qkrTAc01ZMiQOOSQQ95TaiMiunXrFieccEJERDz00ENVmAxorrfeeismTpwYPXr0+J+lNiKUWijE/yq1ERFHHnlkREQsWrRoc47DRmhX7QFonj333DO22mqr+P3vfx9//etfY6eddno3e/jhh+Of//xnjBw5snoDAhvt318It2vnl2aoZQ888ECsWrUqxo0bF23atIl77rkn5s+fH9tss00MGDAgPvvZz1Z7RGAj/fKXv4yIiH79+lV5EprLV0+F2HHHHeP888+P733ve1FfXx8jR46MLl26xOLFi2P69OnxxS9+Ma688spqjwlU6N9/Tj4iYsSIEVWeBsh57LHHIuJfn/T0798/5s+f/578gAMOiDvuuCO6du1ajfGAClxwwQXx+uuvx+rVq+MPf/hDzJ07N/r16xcTJkyo9mg0k2JbkHHjxkWvXr3imGOOiauvvvrdv77HHnvE6NGj/+u3KAPlmDBhQsyfPz8OOuigGD58eLXHATJeeeWViIiYPHly1NfXx69//evYe++9Y+nSpXHKKafEzJkz44gjjvDHCqAgF1xwQaxcufLd/z1ixIiYOnWq/0BVEH/GtiCTJk2Kww8/PEaPHh2LFy+ONWvWxOOPPx59+vSJr33ta3HqqadWe0SgApdeemlceOGF8bGPfSxuuummao8DNOHfa7natWsX06dPj4EDB0aHDh3ik5/8ZPziF7+I7t27x5w5c6zig4KsWLEiGhsbY8WKFXHnnXfGkiVLon///vHHP/6x2qPRTIptIR566KEYP358HHroofGTn/wk+vTpE+3bt4999tknfvGLX8Ruu+0WF154oe+KDIW57LLL4uSTT476+vqYPXt27LjjjtUeCWhC586dIyKif//+0atXr/dk7du3f/d3Xfz+97/fzJMBG2uXXXaJhoaGmDlzZrz66qvxzW9+s9oj0UyKbSHuvvvuiPjXd0B+v/bt28eAAQNiw4YN8cQTT2zu0YAKXXzxxTFmzJjo27dvzJ49O7p161btkYBm+OhHPxoR/19w32+HHXaIiIi1a9durpGAFtazZ8+or6+PZ555Jv76179WexyaQbEtxFtvvRURkVzp8++//r9WDgC15/zzz4/vfve7sffee8fs2bP9GXkoyNChQ6Ouri7+9Kc/vfvbkv/Tv7+ZVO/evTf3aEALevnllyMiom3btlWehOZQbAsxaNCgiIi46qqr4qWXXnpPdt9998VvfvOb2GabbWL//fevxnjAB3DOOefEhAkTYt99941Zs2a9Z30XUPt69uwZhxxySPzlL3+JSy655D3ZzJkzY8aMGdG5c2ff4Rxq3MKFC2P16tX/9dc3bNgQEydOjFdeeSX233//d38XBrWtrrGxsbHaQ9C0DRs2xPDhw+PBBx+M7bffPhoaGqJbt27x7LPPxt133x2NjY1x8cUXx8knn1ztUYGMG264IUaPHh1t27aNMWPGRKdOnf7rx/Tq1StGjx69+YcDmm3ZsmWx//77x4svvhhDhw6N/v37x9KlS+Ouu+6Kurq6uO2222LUqFHVHhPIuPjii+O0006LgQMHRu/evaNLly6xcuXKmDNnTixZsiS6desWs2bNivr6+mqPSjMotgVZt25dXH755XHbbbfFn/70p3jjjTdixx13jAEDBsTYsWNj2LBh1R4RaMKZZ54ZZ511VvbHfP7zn7cmBAqwatWqOPvss2P69OmxfPny6NixYwwaNChOO+20GDBgQLXHA5owf/78mDJlSsydOzeWLVsWr732Wmy33Xax1157xcEHHxxjx471TR0LotgCAABQNH/GFgAAgKIptgAAABRNsQUAAKBoii0AAABFU2wBAAAommILAABA0RRbAAAAitauuT+wrq5uU84BrUatr4Z2l6F5avkuu8fQPLV8jyPcZWiu5txln9gCAABQNMUWAACAoim2AAAAFE2xBQAAoGiKLQAAAEVTbAEAACiaYgsAAEDRFFsAAACKptgCAABQNMUWAACAoim2AAAAFE2xBQAAoGjtqj0AQGsxZMiQZHbmmWdW/N5nnnkmmU2fPj2ZPf7448nslVdeqXgeAIBa4xNbAAAAiqbYAgAAUDTFFgAAgKIptgAAABRNsQUAAKBoii0AAABFU2wBAAAoWl1jY2Njs35gXd2mngVahWZeqapxlzedESNGJLN77713M07yL3/5y1+S2RlnnJF99oYbbmjpcYpTy3fZPY649dZbk1lT/9997Wtfa+lxqFG1fI8j3GVorubcZZ/YAgAAUDTFFgAAgKIptgAAABRNsQUAAKBoii0AAABFU2wBAAAoWrtqDwDQWsyYMSOZdejQoeL3jh8/Ppkdd9xxyaxHjx7J7Nprr82e2aZN+r97Xn/99dlnoaUcdthhyeyII45IZr/61a82xThARv/+/ZPZl770pWQ2duzYZNalS5eNmikl9++x8847L/vs4sWLW3ocWohPbAEAACiaYgsAAEDRFFsAAACKptgCAABQNMUWAACAoim2AAAAFK2usbGxsVk/sK5uU89CAXr16pXNTzzxxGR26qmnJrPcT8NFixZlz/zoRz+azTe3Zl6pqnGXW5du3bols4suuiiZHXXUUdn3rlu3Lpkdf/zxyWzq1KnZ95aklu/ylnKPb7/99mR2+OGHJ7PJkydn3zthwoSKZ6IstXyPI8q6yzfddFM2z/17pW3bti09ziazfv36bH7zzTcns0mTJiWzBQsWVDwTzbvLPrEFAACgaIotAAAARVNsAQAAKJpiCwAAQNEUWwAAAIqm2AIAAFA0635asT322COZDR8+PJmNGjUqmX3605/Ontm+fftklvs5tHTp0mR29NFHZ8+cO3duNt/crBagVuRWAd13333ZZz/1qU8ls9x9HTBgQDJ79dVXs2fWmlq+y63pHufWgMyePTuZfe5zn0tm++yzT/bMp556qunBaBVq+R5H1N5d/va3v53MLr300uyzlf693Hjjjcns0UcfzT57yy23JLM+ffoks9GjRyezkSNHZs/s2bNnMnvzzTeT2THHHJPMcqvN+BfrfgAAAGj1FFsAAACKptgCAABQNMUWAACAoim2AAAAFE2xBQAAoGiKLQAAAEWzx7bG7b777snswAMPzD47efLkZNahQ4dk9sILLySzm266KXvmkCFDkln//v2T2RVXXJHMxo8fnz2z1tiZRwm+/OUvZ/O77rormeV+ju+1117J7Pnnn29yrlpSy3e5Nd3jAw44IJnl9tiuXbs2mTW1x3bhwoVND9YK9O3bN5k1NDQks86dOyezq6++Onvmc8891+Rcm1Mt3+OI2rvL06dPT2YHH3xwxe/dd999k9nTTz+dzN55552Kz6xUx44ds/n3vve9ZPaDH/wgmS1btiyZDR8+PHtmrd2rarDHFgAAgFZPsQUAAKBoii0AAABFU2wBAAAommILAABA0RRbAAAAimbdTw3IrTqYOnVqMuvZs2f2vWvWrElmc+fOTWannHJKMvvqV7+aPfO0005LZpMmTaroudJYLUAJ2rdvn82nTZuWzHJrCX784x8ns9NPP73pwWpILd/l1nSPTzjhhGR2+eWXJ7PXX389mTW17mfx4sVND1Yjcuv5zjzzzOyzY8aMSWbt2rWraJ7c1xYR+Zl+8pOfVHTmxqjlexxRe3d5u+22S2Y/+tGPss9edtllyWzJkiXJbP369U0PVkP69euXzJ544omK3rlgwYJsXl9fX9F7WxPrfgAAAGj1FFsAAACKptgCAABQNMUWAACAoim2AAAAFE2xBQAAoGiVfa93PrDbb789mR100EHJLLeS44wzzsieed111yWzl19+OZmde+65yWzChAkVn9maVvpA6d54441s/sgjjySz3LqfsWPHJrPS1v2wefTo0aOi53Ire0pa5xMR8clPfjKZXXTRRcls8ODBFZ+5cOHCis685JJLsu89++yzk9mDDz6YzObNm5d9L5tHbp1T7td3Ns72229f7RFaBZ/YAgAAUDTFFgAAgKIptgAAABRNsQUAAKBoii0AAABFU2wBAAAomnU/LeTAAw/M5kcccUQyW7RoUTLLfWv1GTNmZM/s2rVrMnvqqaeSWW7tQFMre84///xsDpShTRv/3ZOWscsuu2Tz0aNHb55BqqxTp07J7LLLLktmAwcOTGZ///vfs2eOGzcumeXWEK5bty6Z7bvvvtkzjz322GTWpUuX7LMAG8NXLgAAABRNsQUAAKBoii0AAABFU2wBAAAommILAABA0RRbAAAAiqbYAgAAUDR7bFtI7969s3ljY2My+9a3vpXMHn744WT2sY99LHtmbkdd3759k9mpp56azC6++OLsmUDrkPt1CT6IQYMGZfOm9tym3HXXXRU9Vy0XXnhhMsvtql29enUyy+2pjYi4+eabm5zrg/rEJz7R4u+Eknz84x9v8Xc+99xzLf7OLZFPbAEAACiaYgsAAEDRFFsAAACKptgCAABQNMUWAACAoim2AAAAFM26nxbywAMPZPO1a9cms6lTpyazs846K5mdfvrp2TP33HPPZJZb6XPJJZcks/Xr12fPBMrQs2fPbN6+ffuK3jtt2rSKnqP1+tSnPrVJ3ltrP9eGDRuWzY855phkllsJeO655yazTbHOpyl77733Zj8TUvbff/9k1rFjx4reudtuu2XzyZMnV/TenFtvvbXF37kl8oktAAAARVNsAQAAKJpiCwAAQNEUWwAAAIqm2AIAAFA0xRYAAICiWffTQhYtWpTNJ02alMzOOOOMZHbdddcls7feeit75le+8pVklluTYKUPtH6DBw/O5p06dUpma9asSWa5X8/YMu26667ZvK6uLpndfffdyeyZZ56peKZNIbdGLyL/9zlnzpxkduGFF1Y806aQ+/uIyH9t8tprr7XwNLQGQ4YMSWZnn3129tl+/fols+22267imTaF5cuXJ7N77rlnM07SevnEFgAAgKIptgAAABRNsQUAAKBoii0AAABFU2wBAAAommILAABA0az72UwWLFjQ4u886aSTsvntt9/e4mcC5Rg0aFAya2qFSG5lxze+8Y1k9sILLzQ5F1uWL37xi9m8sbGxoqwacmuwevfunX029/fywAMPVDxTpdq2bZvMhg4dmszatct/6XjeeeclsyeeeKLpwdjinHLKKcnss5/97GacZNPaYYcdkllDQ0P22SuvvLKlx2mVfGILAABA0RRbAAAAiqbYAgAAUDTFFgAAgKIptgAAABRNsQUAAKBoii0AAABFs8d2M7n88suT2RtvvJHM1q1bl8yuueaa7JkzZsxIZi+99FL2WagFX/nKV7L5xIkTk1n37t1bepyIyO+bzO1vXLFiRTJbvnz5Rs2UctRRRyWz3D69iIi77747md11112VjgRF69ixYzLr1avX5hukmdq0SX9+cfTRRyezq6++Opk9+eST2TMnTZrU5Fzwn7baaqtqj/CBrF27NpktXrw4mfXt2zeZXXTRRdkzc3unp02blsxWrlyZfW9r4xNbAAAAiqbYAgAAUDTFFgAAgKIptgAAABRNsQUAAKBoii0AAABFs+6nhUyePDmbt2uX/kc9YMCAZLbffvsls2uvvTZ75jnnnJPMjjvuuGS2fv367HuhJe2+++7J7Prrr88+W40VAaNGjaoo+8c//pHMrrvuuuyZc+bMSWaHHnpoMvvGN76RzHLrhyIifvCDHySz3K9Zu+66azL74x//mD3zxRdfzOZseZYtW1btEWraLrvsks0nTJiQzMaOHZvMXn755WTW1Bq23CoU+F9yK6K6dOmSfXbPPfdMZttuu21F8yxdujSbX3DBBcns5ptvTma5NVpHHnlk9syf/vSnySzXMS699NLse1sbn9gCAABQNMUWAACAoim2AAAAFE2xBQAAoGiKLQAAAEVTbAEAACiadT/v07Zt22Q2ZMiQZHbCCSdk35v7Nt7PPvtsMlu4cGEyO/roo7Nnjh49Opk9/PDDyWzq1KnZ90JLOuWUU5JZU+t8pk2blsxOPvnkZNajR49k9re//S175mc+85lkNnHixGTWtWvXZDZu3LjsmU3lldhhhx2y+b333lvRs7m1RiNGjMiead1PuXIrNzp37lzxe2fPnl3xs5vC22+/ncxef/317LPbb799Msut7cl9/ZD7NSciom/fvsls3rx5ySy30if3dQlUYubMmRVlERFDhw5NZk39ey5l7ty52bypdXkpp59+ejJrat0PzeMTWwAAAIqm2AIAAFA0xRYAAICiKbYAAAAUTbEFAACgaIotAAAARbPu530GDRqUzO6///5kdtBBB2XfO2PGjIrmeeedd5LZG2+8UdE7IyI6dOhQ8bPQkj796U9X/OyUKVOS2csvv1xR1pTcqosbb7wxmTU0NCSz3NqijfHQQw8ls9yvLU1ZtmxZMhszZkwya2odCq1TY2Njxc9uvfXWLTjJxlu5cmUye+yxx7LP5lYGnnTSSRVlTbntttuS2bHHHpvM1q5dW/GZsDnNmjWr2iM02+GHH17tEVo9n9gCAABQNMUWAACAoim2AAAAFE2xBQAAoGiKLQAAAEVTbAEAACiaYgsAAEDRtsg9trvttlsyu/POO5PZ0qVLk1mle2qrZfbs2dUeATbaGWeckcyefPLJZPbmm29WfOYXvvCFZDZy5Mhkdthhh1V85ksvvZTMvvrVryaz3/72t8lsY/bYwvstWrQomc2bNy/77Oc+97lkdsEFF1T03qeffjp7ZqUOPPDAZNa1a9dNcmbOj3/842x+1llnJbO33367pceBLcKHPvShZFZfX5/MjjvuuE0xDv/BJ7YAAAAUTbEFAACgaIotAAAARVNsAQAAKJpiCwAAQNEUWwAAAIq2Ra77uf7665NZu3bpfyQHHHDAphgn6/jjj09mubUDERH3339/Mnv++ecrngla0jnnnJPMpkyZkn124MCByWzVqlUVz7QprFmzJpldd9112WdzKwI2bNhQ8UywOdxyyy3ZvF+/fsls5513TmaPPfZYMmtqxVCnTp2SWW4l4NZbb53M2rTZ/J8VHHnkkdk8t/botttua+lxIGnw4MHJLLci5/bbb8++97XXXktm69evT2a5XwNy63wiIsaMGZPMvv/972efrVRjY2My25gVhq2NT2wBAAAommILAABA0RRbAAAAiqbYAgAAUDTFFgAAgKIptgAAABStrjH3/aP/8wfW1W3qWVrMvvvum80feeSRZPbggw8ms4MOOqjimXK+/e1vJ7OLLroomS1evDj73oaGhmS2YMGCpgejIs28UlVT0l0+/PDDs/mxxx6bzFavXp3Mcisymvr/b/ny5cns3HPPTWYPPPBAMlu0aFH2TKqjlu9ySfe4KcOHD09md9xxRzJr3779phgn6x//+EcyO//887PPTps2LZn1798/mY0aNSqZNfV1Sdu2bZNZ7ted3KrB3/3ud9kza+3e1No879ea7nLOs88+m8z22muvit+bW1v1yiuvJLPDDjssmXXv3r3ieSqV+5olImLChAnJ7KqrrmrpcWpSc+6yT2wBAAAommILAABA0RRbAAAAiqbYAgAAUDTFFgAAgKIptgAAABStVa772W+//bL5b3/722Q2bNiwZDZr1qxktueee2bPzH078k984hPJbM6cOcnsO9/5TvbM559/PpuzaVgtAK1DLd/lLeUe9+3bN5nlVt18/OMfr/jM3DqbmTNnJrMlS5ZUfGalcv98IiJOOumkZNaxY8dkdtRRRyWzDh06ZM9cu3ZtNt/cavkeR2w5d7m+vj6Z5dbhdevWbVOMs8nkfr7deuutySy3ijQi4mc/+1nFM7UW1v0AAADQ6im2AAAAFE2xBQAAoGiKLQAAAEVTbAEAACiaYgsAAEDRFFsAAACKZo/t+9x5553JrE2b9H8HaGhoyJ75+uuvJ7Mf/vCHyeyaa66p6J1Uj5150DrU8l12j6F5avkeR7jLEfkdtw8++GD22V122aWlx2nSypUrk9nZZ5+dzKZMmbIpxtli2GMLAABAq6fYAgAAUDTFFgAAgKIptgAAABRNsQUAAKBoii0AAABFa5Xrfj7ykY9k8zvuuCOZ9evXr6Izb7311mye+/bfixYtquhMapPVAtA61PJddo+heWr5Hke4y9Bc1v0AAADQ6im2AAAAFE2xBQAAoGiKLQAAAEVTbAEAACiaYgsAAEDRWuW6H6gmqwWgdajlu+weQ/PU8j2OcJehuaz7AQAAoNVTbAEAACiaYgsAAEDRFFsAAACKptgCAABQNMUWAACAoim2AAAAFE2xBQAAoGiKLQAAAEVTbAEAACiaYgsAAEDRFFsAAACKptgCAABQNMUWAACAoim2AAAAFE2xBQAAoGiKLQAAAEVTbAEAACiaYgsAAEDRFFsAAACKptgCAABQtLrGxsbGag8BAAAAlfKJLQAAAEVTbAEAACiaYgsAAEDRFFsAAACKptgCAABQNMUWAACAoim2AAAAFE2xBQAAoGiKLQAAAEX7P7IOmQNO5lXzAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see what we have in our validation set\n",
    "mnist_data_loader.valid.show_batch(max_n=4, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>0.535798</td>\n",
       "      <td>0.831667</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.130882</td>\n",
       "      <td>0.073821</td>\n",
       "      <td>0.974917</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training the model, go get a coffee as this will take a while\n",
    "mnist_learner = vision_learner(mnist_data_loader, resnet18, metrics=accuracy)\n",
    "mnist_learner.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ToTensor\n"
     ]
    }
   ],
   "source": [
    "# these were the transformations that were applied to the images at itemlevel when the model was trained\n",
    "print(mnist_data_loader.after_item)\n",
    "\n",
    "# the ouput basically says that each `PIL` image from the dataset has been turned into a tensor,\n",
    "# in this case it's an int tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -> Normalize -- {'mean': tensor([[[[0.4850]],\n",
      "\n",
      "         [[0.4560]],\n",
      "\n",
      "         [[0.4060]]]]), 'std': tensor([[[[0.2290]],\n",
      "\n",
      "         [[0.2240]],\n",
      "\n",
      "         [[0.2250]]]]), 'axes': (0, 2, 3)}\n"
     ]
    }
   ],
   "source": [
    "# these were the transformations that were applied to the images at batch level when the model was trained\n",
    "print(mnist_data_loader.after_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the previous output, several things are happening here:\n",
    "\n",
    "- 1st transformation: the int tensor is converted to a float tensor, models work better with floating point numbers as they can represent a wider range of values\n",
    "- 1st transformation: values in the float tensor are divided by `255.0` to get values between 0 and 1 (normalization), this speeds up the training process\n",
    "- 2nd transformation: the images are normalized again using the _mean_ and _standard deviation_ of the MNIST dataset: `'axes': (0, 2, 3)` means we are calculating the mean and standard deviation for each channel across all images and pixels in those channels; this is why you're not seeing the channel axis here; standard deviation is a measure of how dispersed the set of values is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the learner\n",
    "mnist_learner.export('exported/mnist_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model for export to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloading the learner to avoid running the whole notebook again\n",
    "learner = load_learner('exported/mnist_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yactouat/.local/lib/python3.10/site-packages/fastai/torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  return getattr(torch, 'has_mps', False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('6',\n",
       " tensor([8.1033e-05, 2.4610e-06, 7.0510e-06, 2.2816e-06, 3.8952e-06, 2.4798e-05, 9.9987e-01, 2.0386e-07, 1.1940e-05, 4.8306e-07]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that our exported model can read image matrices as inputs\n",
    "test_img = PILImage.create('example_mnist_6_digit.png')\n",
    "\n",
    "preds, _, probs = learner.predict(test_img)\n",
    "\n",
    "preds, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28), ('R', 'G', 'B'), torch.Size([28, 28, 3]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking what the expected input looks like\n",
    "test_img.shape, test_img.getbands(), tensor(test_img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to create a fake input to be able to export the model,\n",
    "# it is, in our case in the form  => (batch_size, channels, height, width);\n",
    "dummy_input = torch.randn(1, 3, 28, 28)\n",
    "\n",
    "dummy_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloading the model's data loader (necessary for the export to work)\n",
    "learner.dls = mnist_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the underlying pytorch model\n",
    "pytorch_model = learner.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model in ONNX format\n",
    "\n",
    "PyTorch models are exportable in ONNX format, so the first thing to do is to get the underlying PyTorch model from the `fastai` learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the model to evaluation mode,\n",
    "# this means that some normalization and dropout layers will be disabled to ensure a more deterministic behavior\n",
    "pytorch_model.eval()\n",
    "\n",
    "# specify input and output names of the exported model\n",
    "input_names = [\"input_image\"]\n",
    "output_names = [\"digit_prediction\"]\n",
    "\n",
    "# ! choose either MNIST or business model\n",
    "torch.onnx.export(\n",
    "\n",
    "    # moving the model to CPU,\n",
    "    # this ensures that the consuming machine will run inference on the CPU (better portability)\n",
    "    pytorch_model.cpu(),\n",
    "\n",
    "    dummy_input.cpu(), \n",
    "    \n",
    "    'exported/mnist_model.onnx',\n",
    "\n",
    "    # compiler optimizations\n",
    "    do_constant_folding=True,\n",
    "\n",
    "    # store the trained parameter weights inside the model file         \n",
    "    export_params=True,\n",
    "\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "\n",
    "    # indicate which axes of the input and output tensors should be treated as dynamic;\n",
    "    # here, specifying `{0: \"batch_size\"}` for I/O indicates that we will be able to run mass inference with the exported model \n",
    "    dynamic_axes={\n",
    "        'input_image': {0: 'batch_size'},\n",
    "        'digit_prediction': {0: \"batch_size\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating that our ONNX exports works as expected using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is valid!\n"
     ]
    }
   ],
   "source": [
    "model = onnx.load(\"exported/mnist_model.onnx\")\n",
    "try:\n",
    "    onnx.checker.check_model(model)\n",
    "    print(\"The model is valid!\")\n",
    "except onnx.checker.ValidationError as e:\n",
    "    print(f\"The model is invalid: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = ort.InferenceSession(\"exported/mnist_model.onnx\")\n",
    "\n",
    "to_tensor = T.ToTensor()\n",
    "input_data = (to_tensor(test_img)).unsqueeze(0).numpy()\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Digit: [1]\n"
     ]
    }
   ],
   "source": [
    "inputs = {session.get_inputs()[0].name: input_data}\n",
    "outputs = session.run(None, inputs)\n",
    "digit_prediction = outputs[0]\n",
    "predicted_digit = np.argmax(digit_prediction, axis=1)\n",
    "print(\"Predicted Digit:\", predicted_digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have to do is to test how to read this on C# side. \n",
    "\n",
    "It will be necessary to compare the performance of the original model with the exported model to see if there is any discrepancy between the two."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
